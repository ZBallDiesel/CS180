<!DOCTYPE html>
<html>
<head>
    <title>Project 5</title>
    <style>
        body {
            font-family: Times New Roman, Arial, sans-serif;
            margin: 20px;
        }

        <!-- Following code for CSS style is adapted from W3 Schools. https://www.w3schools.com/howto/howto_css_images_side_by_side.asp
        and Stack Overflow
        https://stackoverflow.com/questions/61637178/how-to-center-multiple-figure-elements-in-one-row-->
        * {
      box-sizing: border-box;
    }
    
    .column {
      float: left;
      width: 50%;
      padding: 5px;
    }
    
    
    .row {
      padding-bottom: 50px;
      display: flex;
        text-align: center;
        flex-direction: row;
        justify-content: center;
    }

    img {
        width: 100%;
        height: auto
        
    }
    </style>
</head>

  <body>
    <h1>Welcome to My CS180 Project 5!</h1>
    <a href = "../index.html"> My CS180 Personal Project Home Page </a>
    <strong> <br> Name: Zach Turner <br> SID: 3036700008 </strong>
    <h3>Introduction</h3>

        <p>
            This project works with diffusions models to generate various interesting images with various techniques such as CFG, Anagram generation, and Hybrid images. In part a, we use the DeffFloyd Diffusion model from Stability AI. In part b, we train my own diffusion model to generate MINST digits. 
        </p>

    <h2>Part A</h2>


      <h4>Part 0</h4>
      <p>
          In this section, we are getting familiar with the output of DeepFloyd IF. The model utilizes two stages: the first stage generates 64x64 pixel images and the second stage upsamples the images to 256x256 pixels. For our experimentation, we are using the following three prompts: <br><br>[
    'an oil painting of a snowy mountain village',
    'a man wearing a hat',
    "a rocket ship",
]. <br><br>
          Each stage has a parameter num_steps that controls the number of iterations the diffusion model uses during the denoising process. Using more steps will generate higher quality images but will be computationally more intensive. I will experiment with the output of each stage for a range of step sizes. Below is the output.
      </p>

      <div class = "row">
        <figure>
            <img src = "media/im20Step.jpg">
            <figcaption>Generated Output of Stage 2 with 20 Steps in both Stage 1 and Stage 2</figcaption>
        </figure>

          <figure>
            <img src = "media/im20StepSmall.jpg">
            <figcaption>Generated Output of Stage 1 with 20 Steps in Stage 1 </figcaption>
        </figure>

      </div>

       <div class = "row">
        <figure>
            <img src = "media/im5Step.jpg">
            <figcaption>Generated Output of Stage 2 with 5 Steps in both Stage 1 and Stage 2</figcaption>
        </figure>

          <figure>
            <img src = "media/im5StepSmall.jpg">
            <figcaption>Generated Output of Stage 1 with 5 Steps in Stage 1 </figcaption>
        </figure>

      </div>

       <div class = "row">
        <figure>
            <img src = "media/im50Step.jpg">
            <figcaption>Generated Output of Stage 2 with 50 Steps in both Stage 1 and Stage 2</figcaption>
        </figure>

          <figure>
            <img src = "media/im50StepSmall.jpg">
            <figcaption>Generated Output of Stage 1 with 50 Steps in Stage 1 </figcaption>
        </figure>

      </div>

       <div class = "row">
        <figure>
            <img src = "media/im20Step.jpg">
            <figcaption>Generated Output of Stage 2 with 20 Steps in both Stage 1 and Stage 2</figcaption>
        </figure>

          <figure>
            <img src = "media/im20StepSmall.jpg">
            <figcaption>Generated Output of Stage 1 with 20 Steps in Stage 1 </figcaption>
        </figure>

      </div>
 <div class = "row">
        <figure>
            <img src = "media/im20_5Step.jpg">
            <figcaption>Generated Output of Stage 2 with 20 Steps in Stage 1 and 5 Steps in Stage 2</figcaption>
        </figure>

          <figure>
            <img src = "media/im20_5StepSmall.jpg">
            <figcaption>Generated Output of Stage 1 with 20 Steps in Stage 1 </figcaption>
        </figure>

      </div>

       <div class = "row">
        <figure>
            <img src = "media/im5_20Step.jpg">
            <figcaption>Generated Output of Stage 2 with 5 Steps in Stage 1 and 20 Steps in Stage 2</figcaption>
        </figure>

          <figure>
            <img src = "media/im5_20StepSmall.jpg">
            <figcaption>Generated Output of Stage 1 with 5 Steps in Stage 1 </figcaption>
        </figure>

      </div>

<h5>Interpretation</h5>

      <p>
          Here we try a variety of combinations of 5, 20, 50 steps in stages 1 and 2. In both stages, I notice a large increase in quality moving from 5 to 20 steps and little quality increase moving from 20 to 50 steps. I also noticed that each stage seems to perform a different task. I infer that stage 1 is reposible for generating the "thoughtful" information content - ie the general content of the image and stage 2 performs upsampling that increases the image size while keeping the visual content of the image highly similar to the output of stage 1. In particular, we can see that increases in stage 1 number of steps increases the accuracy and detail in the image's visual content while the number of steps in stage 2 controls the pixel quality and sharpness of its output. 
          <br><br>
          For example, inspect the images that result when there are 20 steps in stage 1 and 5 steps in stage 2. These images have stage 1 output that are consistent to the prompt and are feature high qaulity details while the stage 2 output has odd pixels details with poor image quality.
          <br><br>
          Conversely, consider the images that result with 5 steps in stage 1 and 20 steps in stage 2. The visual content of these images is lacking, supporting the idea that stage 1 creates the visual content. In these images, the mountain village is lacking realism and details in the mountains, the rocket ship is simplistic, and the man in a hat is a rather nonsense image that contains many small hats. However, the stage 2 output with 20 steps is perfectly high quality while retaining the lack of realism in image content from stage 1, which supports the hypothesis that stage 2 determines the upsampled image quality without much effect on visual content. 
      </p>

      <h5>Seeding</h5>
      <p>
          Throughout this projec, I am using the seed 831 with the exception of a few later prompts where I experiment with seed 699 to generate different output. These locations will be noted. 
      </p>
      
<h4>Part 1.1: Implementing the Forward Process </h4>
<p>
    In this section we are noising clean image such that the diffusion model can be trained to denoise them. In this section and following sections, we will be using a photo of the campanile as an clean example image to experiment with. 

The campanile will be x_0, the clean image at time 0. At time t, the noised image will be solved for according to
</p>
<div class = "row">

    <figure>
        <img src = "media/equation.jpg">
    </figure>
</div>

      <p>
          Let's see the output of noising. Below are the images we are working with. On the left, is the clean orignial campanile image. To its right, we have the campanile noised at steps 250, 500, and 750. 
      </p>

      <div class = "row">
        <figure>
            <img src = "media/campanile.jpg">
            <figcaption>Original Clean Image</figcaption>
        </figure>

          <figure>
              <img src = "media/forwardNoised.jpg">
              <figcaption>Noised Images at t = 250, 500, 750</figcaption>
          </figure>
      </div>
      
<h4>Part 1.2: Attempting Classical Denoising</h4>
    <p>
        We know various methods for denoising Gaussian Noise. One such method that we know is Guassian Blurring the noisy images. Lets see how Guassian Blurring handles this noise. 
    </p>

      <div class = "row">
        <figure>
            <img src = "media/classicDenoised15.jpg">
            <figcaption>Noisy images at t = 250, 500, 750 Denoised with Guassian Blur</figcaption>
        </figure>
      </div>

      <p>
          As we can see, Guassian Blurring is unable to denoise the images satisfactorily. In fact, Gaussian Blurring will deliver poor denoising in this situation for any parameter values.
      </p>

      <h4>Part 1.3: One Step Denoising</h4>
      <p>
          Now, we will try a more sophisticated method to denoise the images. We will use the DeepFloyd Diffusion model from Stability AI that has been trained for these alpha values. DeepFloyd uses text embedding; we will use the prompt "a high quality photo" as instructions to denoise the images. We will be using one step denoising where we call the UNet at the t value used to noise the images to estimate the x_0 clean image. Let's see how the UNet does. 
      </p>

      <div class  = "row">
        <figure>
            <img src = "media/1_3results.jpg">
            <figcaption>UNet One Step Denoising Results 
                Columns are as follows: Original Image, Noisy Image, Noise Estimate, DeNoised Image
            The rows are t = 250, 500, 750 descending</figcaption>
        </figure>
      </div>
<h5>Interpretation</h5>
      <p>
          In all cases, the Unet does a generally good job a denoising, certainly better than the Gaussian Blur filter does. We can see that the difference between the denoised output and the original image increases as the level of noise added increases. Since the Unet has to generate more of the image content as the amount of noise increases, this outcome makes sense. Also, the denoised image gets somewhat blurry as the input noise level increases, which is a drawback of one step denoising. 
      </p>
<h3>Part 1.4: Iterative Denoising</h3>
      <p>
          To improve the denoising for highly noised images, we are going to use iterative (multi-step) denoising. DeepFloyd was trained to be used with up to 1000 steps. However, it is not necessary to denoise one step at a time. Instead, we will denoise 30 steps at a time. This allows for us to denoise a noised image noised to at most 990 steps. We can control the starting timestep for denoising with the i_start parameter. 
          <br><br>
          We use iterative denoising to denoise the noisy image of the campanile, which we will compare with our other methods. Below we can see the results of iterative denoising after each 5th loop of denoising, the final clean image after iterative denoising as well as the one step denoised image and the Gaussian filtered image for comparison. Due to ambiguity in the website prompt, I will show the results for denoising from both 690 steps (i_start = 10) and from 990 steps (i_start = 0).
      </p>

      <div class = "row">
        <figure>
            <img src = "media/1_4start10.jpg">
            <figcaption>Iterative Denoising after each 5th loop of denoising (after timesteps 690, 540, 390, 240, 90, 0).<br>
            The right most image is the clean image from iterative denoising</figcaption>
        </figure>
          <figure>
              <img src = "media/1_4oneStep.jpg">
              <figcaption>One Step denoising from t = 690</figcaption>
          </figure>
          <figure>
              <img src = "media/1_4blurFil.jpg">
              <figcaption>Gaussian Filtered Denoised Image from t = 690</figcaption>
          </figure>
      </div>


            <div class = "row">
        <figure>
            <img src = "media/1_4start990.jpg">
            <figcaption>Iterative Denoising after each 5th loop of denoising starting at t = 990 (after timesteps 990, 840, 690, 540, 390, 240, 90, 0).<br>
            The right most image is the clean image from iterative denoising</figcaption>
        </figure>
          <figure>
              <img src = "media/1_4oneStep990.jpg">
              <figcaption>One Step denoising from t = 990</figcaption>
          </figure>
          <figure>
              <img src = "media/1_4blurFil990.jpg">
              <figcaption>Gaussian Filtered Denoised Image from t = 990</figcaption>
          </figure>
      </div>

      <h5>Interpretation</h5>
      <p>
          Add if I have time.
      </p>

      <h3>Part 1.5: Iterative Denoising</h3>
        <p>
            In the last section, we saw how diffusion models can be used to denoise noisy images. However, what will happen if the input image is pure noise? This thought underlies the main use of Diffusion models. Here, we will use this technique to generate new images based on a text prompt. Again, we will use the prompt "a high quality photo" to guide the Diffusion model's image generation. I'll show the results of this strategy in original form and after upsampling and for seeds 831 and 699. 
        </p>

      <div class = "row">
        <figure>
            <img src = "media/1_5ims.jpg">
            <figcaption>Sampled images with seed = 831 and No Upsampling</figcaption>
        </figure>
      </div>

      <div class = "row">
        <figure>
            <img src = "media/1_5oupsampled.jpg">
            <figcaption>Sampled images with seed = 831 and Upsampling</figcaption>
        </figure>
      </div>

      <div class = "row">
        <figure>
            <img src = "media/1_5imsOtherSeed.jpg">
            <figcaption>Sampled images with seed = 699 and No Upsampling</figcaption>
        </figure>
      </div>

      <div class = "row">
        <figure>
            <img src = "media/1_5upsampled.jpg">
            <figcaption>Sampled images with seed = 699 and Upsampling</figcaption>
        </figure>
      </div>

      

      
  </body>
</html>
