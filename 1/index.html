<!DOCTYPE html>
<html>
<head>
    <title>Project 1</title>
    <style>
        body {
            font-family: Times New Roman, Arial, sans-serif;
            margin: 20px;
        }

        <!-- Following code for CSS style is adapted from W3 Schools. https://www.w3schools.com/howto/howto_css_images_side_by_side.asp
        and Stack Overflow
        https://stackoverflow.com/questions/61637178/how-to-center-multiple-figure-elements-in-one-row-->
        * {
      box-sizing: border-box;
    }
    
    .column {
      float: left;
      width: 50%;
      padding: 5px;
    }
    
    
    .row {
      padding-bottom: 50px;
      display: flex;
        text-align: center;
        flex-direction: row;
        justify-content: center;
    }

    img {
        width: 100%;
        height: auto
        
    }
    </style>
</head>
<body>
    <h1>Welcome to My CS180 Project 1!</h1>
    <strong> Name: Zach Turner <br> SID: 3036700008 </strong>
    <h3>Abstract</h3>
    <p> Sergei Mikhailovich Prokudin-Gorskii (1863-1944) [Сергей Михайлович Прокудин-Горский, to his Russian friends] was a man well ahead of his time. Convinced, as early as 1907, that color photography was the wave of the future, he won Tzar's special permission to travel across the vast Russian Empire and take color photographs of everything he saw including the only color portrait of Leo Tolstoy. And he really photographed everything: people, buildings, landscapes, railroads, bridges... thousands of color pictures! His idea was simple: record three exposures of every scene onto a glass plate using a red, a green, and a blue filter. Never mind that there was no way to print color photographs until much later -- he envisioned special projectors to be installed in "multimedia" classrooms all across Russia where the children would be able to learn about their vast country. Alas, his plans never materialized: he left Russia in 1918, right after the revolution, never to return again. Luckily, his RGB glass plate negatives, capturing the last years of the Russian Empire, survived and were purchased in 1948 by the Library of Congress. The LoC has recently digitized the negatives and made them available on-line. 
        <b> <br><br> The goal of this assignment is to take the digitized Prokudin-Gorskii glass plate images and, using image processing techniques, automatically produce a color image with as few 
            visual artifacts as possible. </b></p>
    <h3> Image Pipeline </h3>
    <p> After experimenting in a notebook to determine what techniques were effective, I created a python script image pipeline to load in Prokudin-Gorskii images from .jpg and .tif files in the /data folder and output alinged RGB images. 
    <br> <br>
    My initial step is to load in the images, coerce datatype to uint8 (for .tif images) in order to save memory when computing and have consistency in datatypes between images, and split the image into RGB channels. 
    <br> <br>
    Next, I manually trim the borders of the images before aligning in order to improve the information content of the image channels since the borders largely contain nonsense that is counterproductive to centering. I created a useful function to make this task less labourious: It first displays the image with axes showing overall image size and where features lie in the image; then I can enter the best offsets for each edge of the image--which are then applied to the image. 
        <br><br>
        Now, the image is ready for the centering process. As a note, I use my image pyramid for centering all images. Using my chosen scoring metric, I begin alignment with the smallest image in the pyramid, searching a [-15, 15] pixel range in both dimensions to find the best match between the channels. I then use the optimal centering result just found as a starting point to center the next image down in the pyramid. I continue this pattern until the bottom of the pyramid. 
    
    
    </p>
    <h3> Metrics </h3>
    <p> I tried many different metrics to determine the optimal alignment. I intially tried SSD; however, it did not produce good results. I also tried using the mean value of un-normalized pixels of the correlated image channels due to rounding problems with my early NCC implementations. This worked better than expected, but not as well as NCC. I next tried Normalized Cross Correlation (NCC), which I found to work well across all images when coupled with the correct featurization (detailed in bells and whistles). I also tried using a structural similarity score to align images. This worked well, but did not offer any noticable improvement over NCC while being computationally more expensive. Thus, I chose NCC to be the metric to use for alignment. </p>
    <h4>Interesting note on aligning</h4>
    <p>
        Curiously, I found that the technique used to shift the images matters greatly for getting good results. I initially used a complicated slicing pattern to align the channels that produced only the section of each channel that overlapped when the channels are shifted. This led to a lot of difficulty when actually wanting to take the found shift amounts and calculate the overlapping image. This method also did not scale well to my more advanced implementations, where I scan a [-15, 15] pixel range for each channel (G and B) with each channel having its own starting shift to begin searching from due to the results of the last level of the image pyramid. <b>Most importantly, this method produced mediocre image alignment. </b> I think that this is due to the following reason: when finding the NCC of each particular shift in the search range, the resulting image would be of a different size than for other shifts due to some pixels being cut out. Thus, I had to renormalize each shift, which was slow and did not seem to produce good results. 
        <br>
        <b>A much better and simpler method: </b>
        <br>
        Ultimately, I decided to use np.roll, since it was reccomended by course staff. I intially doubted that this method would work well since it moved pixels to the other side of the image, where they were effectively non-sense. However, I found that this method provided much better results and was much simpler to implement (especially to implement the shifting once the optimal amount has been found)! 

        Now that the alignment step is finished, I simply roll the images using the optimal shifts found by my algorithm. Since this does result in some borders due to pixels being moved to the opposite side of the image from where their meaning lies, I also do small manual crops at this step as well. I use the same method as described above. 
        <br>
        Now, it is time to save our produced image! I also save the amount I shifted each image by and how much I cropped each image by before and after shifting to a pandas dataframe. This makes my images completely reproducible to course staff. I made some nice functionality for this as well. More info will be described elsewhere on this page and in the README.txt file for how to use this to reproduce my images. 
    </p>

    <h2>Enough Text! This class is about images!</h2>
    <h4>Here is a sampling of some of the images produced by my program. </h4>

    <div class = "row">
            
                    <figure>
                <img src= "media/onion_church_no_sobel.jpg" alt = "Onion Church"   >
                <figcaption>G Shift: [-57, -10], B Shift: [-108, -36]</figcaption>
            </figure>
      
       
                    <figure>
                <img src= "media/church_no_sobel.jpg" alt = "Church"   >
                <figcaption>G Shift: [-57, -10], B Shift: [-108, -36]</figcaption>
            </figure>
           
    </div>

    <div class = "row">
            
                    <figure>
                <img src= "media/lady_no_sobel.jpg" alt = "Lady"  >
                <figcaption>G Shift: [-57, -10], B Shift: [-108, -36] <br> 
                Notice that my algorithm does well even with the infamously difficult Lady image. </figcaption>
            </figure>
           
       
                    <figure>
                <img src= "media/icon_no_sobel.jpg" alt = "Icon - Palace?"   >
                <figcaption>G Shift: [-57, -10], B Shift: [-108, -36]</figcaption>
            </figure>
           
    </div>

    <div class = "row">
            
                    <figure>
                <img src= "media/self_potrait_no_sobel.jpg" alt = "Self Portrait!"   >
                <figcaption>G Shift: [-57, -10], B Shift: [-108, -36]</figcaption>
            </figure>
         
       
                    <figure>
                <img src= "media/three_generations_no_sobel.jpg" alt = "Three Generations" >
                <figcaption>G Shift: [-57, -10], B Shift: [-108, -36]</figcaption>
            </figure>
            
    </div>

    <div class = "row">
            
                    <figure>
                <img src= "media/train_no_sobel.jpg" alt = "Train"   >
                <figcaption>G Shift: [-57, -10], B Shift: [-108, -36]</figcaption>
            </figure>
            
       
                    <figure>
                <img src= "media/melons_no_sobel.jpg" alt = "Melons"   >
                <figcaption>G Shift: [-57, -10], B Shift: [-108, -36]</figcaption>
            </figure>
            
    </div>


    <h4>Smaller Images</h4>
    <div class = "row">
            
                    <figure>
                <img src= "media/monastery_no_sobel.jpg" alt = "Monastery"   >
                <figcaption>G Shift: [-57, -10], B Shift: [-108, -36]</figcaption>
            </figure>
            
       
                    <figure>
                <img src= "media/cathedral_no_sobel.jpg" alt = "Cathedral"   >
                <figcaption>G Shift: [-57, -10], B Shift: [-108, -36]</figcaption>
            </figure>
            
    </div>
           

    <h3>Bells and Whistles</h3>
    <h4>Edge Detection (Better Features)</h4>
    <p>
    I tried several forms of edge detection, which noticeably improved image quality for some images. For edge detection, I used both a Sobel filter to detect edges and the image, as well as a Canny filter. A Sobel filter works by combining vertical and horizontal derivatives to find the overall magnitude of the derivative in each pixel of the image. These derivatives calculate how the image is changing at each pixel, allowing edges to be located. These edges provide superior information to match the image channels. I used the Sobel filter function from sk image, and then ran the identical image alignment process using the Sobel filtered image instead of the raw pixels. 
<br><br>
        I also tried a Canny filter, which is a refinement of the Sobel filter that isolates the edges with the most change to remove noise. However, I did not find any images where the Canny filter outperformed the Sobel filter. Since the Canny filter is more computationally expensive, I decided to use Sobel filtering for edge detection in my final implementation. 
        
    </p>
    <h4>Below are Images Where Sobel filtering improved alignment:</h4>

    <div class = "row">
            
                    <figure>
                <img src= "media/emir_no_sobel.jpg" alt = "EMIR"   >
                <figcaption>G Shift: [-57, -10], B Shift: [-108, -36]
                <br> Without Sobel Filtering</figcaption>
            </figure>
            
       
                    <figure>
                <img src= "media/emir_with_sobel.jpg" alt = "EMIR"   >
                <figcaption>G Shift: [-57, -10], B Shift: [-108, -36]
                <br> With Sobel Filtering</figcaption>
            </figure>

        
            
    </div>

    <div class = "row">
            
                    <figure>
                <img src= "media/tobolsk_no_sobel.jpg" alt = "Tobolsk"   >
                <figcaption>G Shift: [-57, -10], B Shift: [-108, -36]
                <br> Without Sobel Filtering</figcaption>
            </figure>
            
       
                    <figure>
                <img src= "media/tobolsk_with_sobel.jpg" alt = "Tobolsk"   >
                <figcaption>G Shift: [-57, -10], B Shift: [-108, -36]
                <br> With Sobel Filtering</figcaption>
            </figure>

        
            
    </div>
    <h4>Commentary</h4>
    <p>

        We can see the biggest improvement from Sobel Filtering in the Emir image. We can see that the Non-Sobel filtered image makes some 
    unreasonably large moves on one channel. This results in a yellow Emir existing on the right hand side of the image, which is terribly mis-aligned. On the Sobel-filtered version, Emir is aligned nicely and the image looks <b>VERY NICE!</b>
        <br><br>
        The tobolsk image also benefitted from the Sobel Filtering, albeit in a less extreme manner than Emir: In the non Sobel version, notice the green noise on the building on the center right of the image, as well as some color noise around the edges of the logs. This is evidence that the alignment is not quite perfert. Notice that these imperfection are absent on the Sobel filtered version, yielding a case where Sobel filtering supplied superior alignment and image quality. 
    </p>
    
    
    <h4>Credits: </h4>
    <p>
        I consulted some external resoures when creating this website for instructions on how to write HTML and CSS code. Some of my webpage code is adapted from https://www.w3schools.com/howto/howto_css_images_side_by_side.asp and https://stackoverflow.com/questions/12912048/how-to-maintain-aspect-ratio-using-html-img-tag. 
        <b>I would like to emphasize that all of the code for image processing is of my own creation.</b>
    </p>

</body>
</html>
